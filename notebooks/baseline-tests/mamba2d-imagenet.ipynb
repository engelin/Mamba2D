{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:19:26.333669Z",
     "iopub.status.busy": "2025-05-20T07:19:26.333397Z",
     "iopub.status.idle": "2025-05-20T07:19:28.147015Z",
     "shell.execute_reply": "2025-05-20T07:19:28.146110Z",
     "shell.execute_reply.started": "2025-05-20T07:19:26.333651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mamba2D'...\n",
      "remote: Enumerating objects: 56, done.\u001b[K\n",
      "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 56 (delta 10), reused 51 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (56/56), 4.52 MiB | 11.00 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/engelin/Mamba2D.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:03:12.037054Z",
     "iopub.status.busy": "2025-05-20T10:03:12.036896Z",
     "iopub.status.idle": "2025-05-20T10:03:12.044523Z",
     "shell.execute_reply": "2025-05-20T10:03:12.043847Z",
     "shell.execute_reply.started": "2025-05-20T10:03:12.037040Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Mamba2D\n"
     ]
    }
   ],
   "source": [
    "%cd Mamba2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:03:17.320878Z",
     "iopub.status.busy": "2025-05-20T10:03:17.320380Z",
     "iopub.status.idle": "2025-05-20T10:04:46.270800Z",
     "shell.execute_reply": "2025-05-20T10:04:46.270093Z",
     "shell.execute_reply.started": "2025-05-20T10:03:17.320857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.0.15)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
      "Collecting lightning (from -r requirements.txt (line 4))\n",
      "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.21.0+cu124)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.7.1)\n",
      "Collecting pathlib2 (from -r requirements.txt (line 7))\n",
      "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting schedulefree (from -r requirements.txt (line 8))\n",
      "  Downloading schedulefree-1.4.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.19.9)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.13.6)\n",
      "Collecting jsonargparse[signatures] (from -r requirements.txt (line 13))\n",
      "  Downloading jsonargparse-4.40.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (0.31.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning->-r requirements.txt (line 4)) (0.14.3)\n",
      "Collecting packaging<25.0,>=20.0 (from lightning->-r requirements.txt (line 4))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning->-r requirements.txt (line 4)) (2.5.1.post0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 5)) (11.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pathlib2->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 11)) (75.2.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 12)) (4.9.3)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from jsonargparse[signatures]->-r requirements.txt (line 13)) (0.16)\n",
      "Collecting typeshed-client>=2.3.0 (from jsonargparse[signatures]->-r requirements.txt (line 13))\n",
      "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (3.11.18)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (4.0.12)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 11)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2025.4.26)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from typeshed-client>=2.3.0->jsonargparse[signatures]->-r requirements.txt (line 13)) (6.5.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r requirements.txt (line 4)) (1.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (5.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->-r requirements.txt (line 5)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->-r requirements.txt (line 5)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->-r requirements.txt (line 5)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->-r requirements.txt (line 5)) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
      "Downloading schedulefree-1.4.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonargparse-4.40.0-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.3/224.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typeshed-client, pathlib2, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, jsonargparse, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, schedulefree, lightning\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jsonargparse-4.40.0 lightning-2.5.1.post0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 pathlib2-2.3.7.post1 schedulefree-1.4.1 typeshed-client-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:04:58.712942Z",
     "iopub.status.busy": "2025-05-20T10:04:58.712156Z",
     "iopub.status.idle": "2025-05-20T10:04:58.833869Z",
     "shell.execute_reply": "2025-05-20T10:04:58.833139Z",
     "shell.execute_reply.started": "2025-05-20T10:04:58.712909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t  wavefront_cuda.cpython-311-x86_64-linux-gnu.so  wf_cuda.cu\n",
      "setup.py  wf_cuda_bind.cpp\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/Mamba2D/models/kernels/wf_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:23:43.605392Z",
     "iopub.status.busy": "2025-05-20T07:23:43.604645Z",
     "iopub.status.idle": "2025-05-20T07:23:43.611629Z",
     "shell.execute_reply": "2025-05-20T07:23:43.610784Z",
     "shell.execute_reply.started": "2025-05-20T07:23:43.605352Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Mamba2D/models/kernels/wf_cuda\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Mamba2D/models/kernels/wf_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:23:46.840691Z",
     "iopub.status.busy": "2025-05-20T07:23:46.840398Z",
     "iopub.status.idle": "2025-05-20T07:25:14.300371Z",
     "shell.execute_reply": "2025-05-20T07:25:14.299694Z",
     "shell.execute_reply.started": "2025-05-20T07:23:46.840669Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n",
      "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
      "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "Emitting ninja build file /kaggle/working/Mamba2D/models/kernels/wf_cuda/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF /kaggle/working/Mamba2D/models/kernels/wf_cuda/build/temp.linux-x86_64-cpython-311/wf_cuda_bind.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Mamba2D/models/kernels/wf_cuda/wf_cuda_bind.cpp -o /kaggle/working/Mamba2D/models/kernels/wf_cuda/build/temp.linux-x86_64-cpython-311/wf_cuda_bind.o -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=wavefront_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/Mamba2D/models/kernels/wf_cuda/build/temp.linux-x86_64-cpython-311/wf_cuda.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Mamba2D/models/kernels/wf_cuda/wf_cuda.cu -o /kaggle/working/Mamba2D/models/kernels/wf_cuda/build/temp.linux-x86_64-cpython-311/wf_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 --use_fast_math -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -lineinfo -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=wavefront_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n"
     ]
    }
   ],
   "source": [
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:25:24.792452Z",
     "iopub.status.busy": "2025-05-20T07:25:24.791856Z",
     "iopub.status.idle": "2025-05-20T07:25:24.910332Z",
     "shell.execute_reply": "2025-05-20T07:25:24.909478Z",
     "shell.execute_reply.started": "2025-05-20T07:25:24.792419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 10276\n",
      "drwxr-xr-x 3 root root     4096 May 20 07:25 .\n",
      "drwxr-xr-x 3 root root     4096 May 20 07:19 ..\n",
      "drwxr-xr-x 4 root root     4096 May 20 07:25 build\n",
      "-rw-r--r-- 1 root root      726 May 20 07:19 setup.py\n",
      "-rwxr-xr-x 1 root root 10486904 May 20 07:25 wavefront_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "-rw-r--r-- 1 root root     1612 May 20 07:19 wf_cuda_bind.cpp\n",
      "-rw-r--r-- 1 root root     9379 May 20 07:19 wf_cuda.cu\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:05:06.737354Z",
     "iopub.status.busy": "2025-05-20T10:05:06.736599Z",
     "iopub.status.idle": "2025-05-20T10:05:06.742867Z",
     "shell.execute_reply": "2025-05-20T10:05:06.742222Z",
     "shell.execute_reply.started": "2025-05-20T10:05:06.737312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Mamba2D\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Mamba2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:05:09.159026Z",
     "iopub.status.busy": "2025-05-20T10:05:09.158515Z",
     "iopub.status.idle": "2025-05-20T10:05:16.684574Z",
     "shell.execute_reply": "2025-05-20T10:05:16.683409Z",
     "shell.execute_reply.started": "2025-05-20T10:05:09.159000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft==0.11.1\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (1.5.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.31.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.11.1) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.11.1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.11.1) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft==0.11.1) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft==0.11.1) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2025.4.26)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft==0.11.1) (2024.2.0)\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft, bitsandbytes\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "Successfully installed bitsandbytes-0.45.5 peft-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.11.1 bitsandbytes torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:05:16.686705Z",
     "iopub.status.busy": "2025-05-20T10:05:16.686389Z",
     "iopub.status.idle": "2025-05-20T10:05:22.077853Z",
     "shell.execute_reply": "2025-05-20T10:05:22.077127Z",
     "shell.execute_reply.started": "2025-05-20T10:05:16.686679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip wheel ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:05:22.079459Z",
     "iopub.status.busy": "2025-05-20T10:05:22.079161Z",
     "iopub.status.idle": "2025-05-20T10:05:55.429364Z",
     "shell.execute_reply": "2025-05-20T10:05:55.428677Z",
     "shell.execute_reply.started": "2025-05-20T10:05:22.079433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==65.5.1\n",
      "  Downloading setuptools-65.5.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-65.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==65.5.1 --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torch.compile` 비활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:05:55.430639Z",
     "iopub.status.busy": "2025-05-20T10:05:55.430439Z",
     "iopub.status.idle": "2025-05-20T10:05:55.434655Z",
     "shell.execute_reply": "2025-05-20T10:05:55.434082Z",
     "shell.execute_reply.started": "2025-05-20T10:05:55.430618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_COMPILE\"] = \"0\"\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE_MAX_AUTOTUNE_GEMM\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAM10000 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:07:46.623076Z",
     "iopub.status.busy": "2025-05-20T10:07:46.622816Z",
     "iopub.status.idle": "2025-05-20T10:07:46.751717Z",
     "shell.execute_reply": "2025-05-20T10:07:46.751078Z",
     "shell.execute_reply.started": "2025-05-20T10:07:46.623055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham10000_images_part_1\tHAM10000_images_part_2\thmnist_28_28_RGB.csv\n",
      "HAM10000_images_part_1\tHAM10000_metadata.csv\thmnist_8_8_L.csv\n",
      "ham10000_images_part_2\thmnist_28_28_L.csv\thmnist_8_8_RGB.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:07:48.756734Z",
     "iopub.status.busy": "2025-05-20T10:07:48.756073Z",
     "iopub.status.idle": "2025-05-20T10:07:57.829180Z",
     "shell.execute_reply": "2025-05-20T10:07:57.828438Z",
     "shell.execute_reply.started": "2025-05-20T10:07:48.756705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\n",
    "class HAM10K(Dataset):\n",
    "    def __init__(self, root=\"/kaggle/input/skin-cancer-mnist-ham10000\", csv=\"HAM10000_metadata.csv\", transform=None):\n",
    "        self.root = root\n",
    "        csv_path = os.path.join(root, csv)\n",
    "        \n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at {csv_path}\")\n",
    "            \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        logger.info(f\"Loaded {len(self.df)} images from {csv_path}\")\n",
    "        \n",
    "        # dx 클래스를 숫자 인덱스로 매핑\n",
    "        self.dx_to_idx = {dx: idx for idx, dx in enumerate(sorted(self.df['dx'].unique()))}\n",
    "        self.df['dx_idx'] = self.df['dx'].map(self.dx_to_idx)\n",
    "        \n",
    "        # 이미지 경로 생성 - image_id를 기반으로 경로 구성\n",
    "        self.df['image_path'] = self.df['image_id'].apply(\n",
    "            lambda img_id: self._get_image_path(img_id)\n",
    "        )\n",
    "        \n",
    "        # 이미지 경로가 유효한지 확인\n",
    "        valid_paths = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path = row.image_path\n",
    "            if os.path.exists(img_path):\n",
    "                valid_paths.append(idx)\n",
    "            elif os.path.exists(os.path.join(root, img_path)):\n",
    "                # 상대 경로로 수정\n",
    "                self.df.at[idx, 'image_path'] = os.path.join(root, img_path)\n",
    "                valid_paths.append(idx)\n",
    "                \n",
    "        if len(valid_paths) < len(self.df):\n",
    "            logger.warning(f\"Only {len(valid_paths)}/{len(self.df)} images exist. Filtering dataset.\")\n",
    "            self.df = self.df.iloc[valid_paths].reset_index(drop=True)\n",
    "        \n",
    "        # 피부 병변에 특화된 변환 추가\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "                transforms.RandomVerticalFlip(),    # 수직 뒤집기\n",
    "                transforms.RandomRotation(20),      # 회전\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1), # 피부색 변화 적용\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "            \n",
    "        # 클래스 분포 확인\n",
    "        class_dist = self.df[\"dx_idx\"].value_counts()\n",
    "        logger.info(f\"Class distribution: {class_dist.to_dict()}\")\n",
    "        logger.info(f\"dx to index mapping: {self.dx_to_idx}\")\n",
    "\n",
    "    def _get_image_path(self, image_id):\n",
    "        \"\"\"image_id를 사용하여 이미지 경로를 생성\"\"\"\n",
    "        # 먼저 HAM10000_images_part_1 폴더에서 확인\n",
    "        path1 = os.path.join(self.root, \"HAM10000_images_part_1\", f\"{image_id}.jpg\")\n",
    "        if os.path.exists(path1):\n",
    "            return path1\n",
    "        \n",
    "        # 그 다음 HAM10000_images_part_2 폴더에서 확인\n",
    "        path2 = os.path.join(self.root, \"HAM10000_images_part_2\", f\"{image_id}.jpg\")\n",
    "        if os.path.exists(path2):\n",
    "            return path2\n",
    "        \n",
    "        # 기본 경로 (검증 단계에서 필터링될 수 있음)\n",
    "        return os.path.join(self.root, \"HAM10000_images\", f\"{image_id}.jpg\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try:\n",
    "            img = Image.open(row.image_path).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            return img, torch.tensor(row.dx_idx)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {row.image_path}: {e}\")\n",
    "            # 에러 발생시 랜덤 이미지 반환 대신 인덱스 재시도\n",
    "            rand_idx = np.random.randint(0, len(self.df))\n",
    "            return self.__getitem__(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:07:57.831091Z",
     "iopub.status.busy": "2025-05-20T10:07:57.830711Z",
     "iopub.status.idle": "2025-05-20T10:07:57.836356Z",
     "shell.execute_reply": "2025-05-20T10:07:57.835684Z",
     "shell.execute_reply.started": "2025-05-20T10:07:57.831062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(dataset, batch_size=4, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"데이터셋을 훈련/검증/테스트로 분할하여 데이터로더 생성\"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    val_size = int(val_ratio * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # 재현성 유지\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, \n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Created data loaders with {len(train_dataset)} train, \"\n",
    "                f\"{len(val_dataset)} validation, and {len(test_dataset)} test samples\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:08:03.284762Z",
     "iopub.status.busy": "2025-05-20T10:08:03.284270Z",
     "iopub.status.idle": "2025-05-20T10:08:55.710643Z",
     "shell.execute_reply": "2025-05-20T10:08:55.709855Z",
     "shell.execute_reply.started": "2025-05-20T10:08:03.284741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "try:\n",
    "    dataset = HAM10K()\n",
    "    train_dl, val_dl, test_dl = create_data_loaders(dataset)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create dataset: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-18T15:41:24.401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# def create_k_fold_loaders(dataset, n_splits=5, batch_size=32, seed=42):\n",
    "#     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "#     X = np.arange(len(dataset))  # 인덱스\n",
    "#     y = dataset.df[\"dx_idx\"].values  # 클래스 레이블\n",
    "\n",
    "#     for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "#         train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "#         val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "#         train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "#         val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#         yield fold, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba2D + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:08:55.712335Z",
     "iopub.status.busy": "2025-05-20T10:08:55.711957Z",
     "iopub.status.idle": "2025-05-20T10:08:57.709651Z",
     "shell.execute_reply": "2025-05-20T10:08:57.708921Z",
     "shell.execute_reply.started": "2025-05-20T10:08:55.712309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (65.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightning\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:08:57.710981Z",
     "iopub.status.busy": "2025-05-20T10:08:57.710674Z",
     "iopub.status.idle": "2025-05-20T10:09:29.584157Z",
     "shell.execute_reply": "2025-05-20T10:09:29.583524Z",
     "shell.execute_reply.started": "2025-05-20T10:08:57.710948Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 10:09:13.430610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747735753.897862      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747735754.016558      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Successfully loaded Mamba2DBackbone\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as L\n",
    "from models.mamba2d import Mamba2DBackbone\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# 모델 빌드 파라미터 설정\n",
    "model_kwargs = {\n",
    "    \"in_channels\": 3,\n",
    "    \"n_blocks\": [3, 3, 9, 3],\n",
    "    \"ds_stages\": [\"mf_stem\", \"mf_2\", \"mf_2\", \"mf_2\"],\n",
    "    \"embed_dim\": [64, 128, 320, 512],\n",
    "    \"token_mixer\": [\"2D\", \"2D\", \"Attention\", \"Attention\"],\n",
    "    \"featmaps_out\": False,\n",
    "    \"drop_path_rate\": 0.1,\n",
    "    \"res_scale_init_values\": [None, None, 1.0, 1.0],\n",
    "}\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "try:\n",
    "    backbone = Mamba2DBackbone(**model_kwargs)\n",
    "    # backbone = backbone.to(dtype=torch.float16).cuda()  # GPU 사용\n",
    "    backbone = backbone.cuda()\n",
    "    print(\"[INFO] Successfully loaded Mamba2DBackbone\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load Mamba2DBackbone: {e}\")\n",
    "    raise\n",
    "\n",
    "# LoRA 설정\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\n",
    "        \"token_mixer.in_proj\", \"token_mixer.x_proj\",\n",
    "        \"token_mixer.dt_projT\", \"token_mixer.dt_projL\",\n",
    "        \"token_mixer.out_proj\",               # Mamba block\n",
    "        \"token_mixer.qkv\", \"token_mixer.proj\" # Attention block\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=None  # Vision 모델일 때는 task_type을 지정하지 않아야 함 ?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:09:29.585760Z",
     "iopub.status.busy": "2025-05-20T10:09:29.585300Z",
     "iopub.status.idle": "2025-05-20T10:09:29.592155Z",
     "shell.execute_reply": "2025-05-20T10:09:29.591376Z",
     "shell.execute_reply.started": "2025-05-20T10:09:29.585741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ds\n",
      "ds.stem\n",
      "ds.stem.pre_norm\n",
      "ds.stem.conv\n",
      "ds.stem.post_norm\n",
      "ds.stem.post_norm.norm\n",
      "ds.ds1\n",
      "ds.ds1.pre_norm\n",
      "ds.ds1.pre_norm.norm\n",
      "ds.ds1.conv\n",
      "ds.ds1.post_norm\n",
      "ds.ds2\n",
      "ds.ds2.pre_norm\n",
      "ds.ds2.pre_norm.norm\n",
      "ds.ds2.conv\n",
      "ds.ds2.post_norm\n",
      "ds.ds3\n",
      "ds.ds3.pre_norm\n",
      "ds.ds3.pre_norm.norm\n",
      "ds.ds3.conv\n",
      "ds.ds3.post_norm\n",
      "stages\n",
      "stages.0\n",
      "stages.0.0\n",
      "stages.0.0.norm1\n",
      "stages.0.0.token_mixer\n",
      "stages.0.0.token_mixer.in_proj\n",
      "stages.0.0.token_mixer.act1\n",
      "stages.0.0.token_mixer.x_proj\n",
      "stages.0.0.token_mixer.dt_projT\n",
      "stages.0.0.token_mixer.dt_projL\n",
      "stages.0.0.token_mixer.act2\n",
      "stages.0.0.token_mixer.out_proj\n",
      "stages.0.0.drop_path1\n",
      "stages.0.0.res_scale1\n",
      "stages.0.0.norm2\n",
      "stages.0.0.MLP\n",
      "stages.0.0.MLP.fc1\n",
      "stages.0.0.MLP.act\n",
      "stages.0.0.MLP.drop1\n",
      "stages.0.0.MLP.fc2\n",
      "stages.0.0.MLP.drop2\n",
      "stages.0.0.drop_path2\n",
      "stages.0.0.res_scale2\n",
      "stages.0.1\n",
      "stages.0.1.norm1\n",
      "stages.0.1.token_mixer\n",
      "stages.0.1.token_mixer.in_proj\n",
      "stages.0.1.token_mixer.act1\n",
      "stages.0.1.token_mixer.x_proj\n",
      "stages.0.1.token_mixer.dt_projT\n",
      "stages.0.1.token_mixer.dt_projL\n",
      "stages.0.1.token_mixer.act2\n",
      "stages.0.1.token_mixer.out_proj\n",
      "stages.0.1.drop_path1\n",
      "stages.0.1.res_scale1\n",
      "stages.0.1.norm2\n",
      "stages.0.1.MLP\n",
      "stages.0.1.MLP.fc1\n",
      "stages.0.1.MLP.act\n",
      "stages.0.1.MLP.drop1\n",
      "stages.0.1.MLP.fc2\n",
      "stages.0.1.MLP.drop2\n",
      "stages.0.1.drop_path2\n",
      "stages.0.1.res_scale2\n",
      "stages.0.2\n",
      "stages.0.2.norm1\n",
      "stages.0.2.token_mixer\n",
      "stages.0.2.token_mixer.in_proj\n",
      "stages.0.2.token_mixer.act1\n",
      "stages.0.2.token_mixer.x_proj\n",
      "stages.0.2.token_mixer.dt_projT\n",
      "stages.0.2.token_mixer.dt_projL\n",
      "stages.0.2.token_mixer.act2\n",
      "stages.0.2.token_mixer.out_proj\n",
      "stages.0.2.drop_path1\n",
      "stages.0.2.res_scale1\n",
      "stages.0.2.norm2\n",
      "stages.0.2.MLP\n",
      "stages.0.2.MLP.fc1\n",
      "stages.0.2.MLP.act\n",
      "stages.0.2.MLP.drop1\n",
      "stages.0.2.MLP.fc2\n",
      "stages.0.2.MLP.drop2\n",
      "stages.0.2.drop_path2\n",
      "stages.0.2.res_scale2\n",
      "stages.1\n",
      "stages.1.0\n",
      "stages.1.0.norm1\n",
      "stages.1.0.token_mixer\n",
      "stages.1.0.token_mixer.in_proj\n",
      "stages.1.0.token_mixer.act1\n",
      "stages.1.0.token_mixer.x_proj\n",
      "stages.1.0.token_mixer.dt_projT\n",
      "stages.1.0.token_mixer.dt_projL\n",
      "stages.1.0.token_mixer.act2\n",
      "stages.1.0.token_mixer.out_proj\n",
      "stages.1.0.drop_path1\n",
      "stages.1.0.res_scale1\n",
      "stages.1.0.norm2\n",
      "stages.1.0.MLP\n",
      "stages.1.0.MLP.fc1\n",
      "stages.1.0.MLP.act\n",
      "stages.1.0.MLP.drop1\n",
      "stages.1.0.MLP.fc2\n",
      "stages.1.0.MLP.drop2\n",
      "stages.1.0.drop_path2\n",
      "stages.1.0.res_scale2\n",
      "stages.1.1\n",
      "stages.1.1.norm1\n",
      "stages.1.1.token_mixer\n",
      "stages.1.1.token_mixer.in_proj\n",
      "stages.1.1.token_mixer.act1\n",
      "stages.1.1.token_mixer.x_proj\n",
      "stages.1.1.token_mixer.dt_projT\n",
      "stages.1.1.token_mixer.dt_projL\n",
      "stages.1.1.token_mixer.act2\n",
      "stages.1.1.token_mixer.out_proj\n",
      "stages.1.1.drop_path1\n",
      "stages.1.1.res_scale1\n",
      "stages.1.1.norm2\n",
      "stages.1.1.MLP\n",
      "stages.1.1.MLP.fc1\n",
      "stages.1.1.MLP.act\n",
      "stages.1.1.MLP.drop1\n",
      "stages.1.1.MLP.fc2\n",
      "stages.1.1.MLP.drop2\n",
      "stages.1.1.drop_path2\n",
      "stages.1.1.res_scale2\n",
      "stages.1.2\n",
      "stages.1.2.norm1\n",
      "stages.1.2.token_mixer\n",
      "stages.1.2.token_mixer.in_proj\n",
      "stages.1.2.token_mixer.act1\n",
      "stages.1.2.token_mixer.x_proj\n",
      "stages.1.2.token_mixer.dt_projT\n",
      "stages.1.2.token_mixer.dt_projL\n",
      "stages.1.2.token_mixer.act2\n",
      "stages.1.2.token_mixer.out_proj\n",
      "stages.1.2.drop_path1\n",
      "stages.1.2.res_scale1\n",
      "stages.1.2.norm2\n",
      "stages.1.2.MLP\n",
      "stages.1.2.MLP.fc1\n",
      "stages.1.2.MLP.act\n",
      "stages.1.2.MLP.drop1\n",
      "stages.1.2.MLP.fc2\n",
      "stages.1.2.MLP.drop2\n",
      "stages.1.2.drop_path2\n",
      "stages.1.2.res_scale2\n",
      "stages.2\n",
      "stages.2.0\n",
      "stages.2.0.norm1\n",
      "stages.2.0.token_mixer\n",
      "stages.2.0.token_mixer.qkv\n",
      "stages.2.0.token_mixer.attn_drop\n",
      "stages.2.0.token_mixer.proj\n",
      "stages.2.0.token_mixer.proj_drop\n",
      "stages.2.0.drop_path1\n",
      "stages.2.0.res_scale1\n",
      "stages.2.0.norm2\n",
      "stages.2.0.MLP\n",
      "stages.2.0.MLP.fc1\n",
      "stages.2.0.MLP.act\n",
      "stages.2.0.MLP.drop1\n",
      "stages.2.0.MLP.fc2\n",
      "stages.2.0.MLP.drop2\n",
      "stages.2.0.drop_path2\n",
      "stages.2.0.res_scale2\n",
      "stages.2.1\n",
      "stages.2.1.norm1\n",
      "stages.2.1.token_mixer\n",
      "stages.2.1.token_mixer.qkv\n",
      "stages.2.1.token_mixer.attn_drop\n",
      "stages.2.1.token_mixer.proj\n",
      "stages.2.1.token_mixer.proj_drop\n",
      "stages.2.1.drop_path1\n",
      "stages.2.1.res_scale1\n",
      "stages.2.1.norm2\n",
      "stages.2.1.MLP\n",
      "stages.2.1.MLP.fc1\n",
      "stages.2.1.MLP.act\n",
      "stages.2.1.MLP.drop1\n",
      "stages.2.1.MLP.fc2\n",
      "stages.2.1.MLP.drop2\n",
      "stages.2.1.drop_path2\n",
      "stages.2.1.res_scale2\n",
      "stages.2.2\n",
      "stages.2.2.norm1\n",
      "stages.2.2.token_mixer\n",
      "stages.2.2.token_mixer.qkv\n",
      "stages.2.2.token_mixer.attn_drop\n",
      "stages.2.2.token_mixer.proj\n",
      "stages.2.2.token_mixer.proj_drop\n",
      "stages.2.2.drop_path1\n",
      "stages.2.2.res_scale1\n",
      "stages.2.2.norm2\n",
      "stages.2.2.MLP\n",
      "stages.2.2.MLP.fc1\n",
      "stages.2.2.MLP.act\n",
      "stages.2.2.MLP.drop1\n",
      "stages.2.2.MLP.fc2\n",
      "stages.2.2.MLP.drop2\n",
      "stages.2.2.drop_path2\n",
      "stages.2.2.res_scale2\n",
      "stages.2.3\n",
      "stages.2.3.norm1\n",
      "stages.2.3.token_mixer\n",
      "stages.2.3.token_mixer.qkv\n",
      "stages.2.3.token_mixer.attn_drop\n",
      "stages.2.3.token_mixer.proj\n",
      "stages.2.3.token_mixer.proj_drop\n",
      "stages.2.3.drop_path1\n",
      "stages.2.3.res_scale1\n",
      "stages.2.3.norm2\n",
      "stages.2.3.MLP\n",
      "stages.2.3.MLP.fc1\n",
      "stages.2.3.MLP.act\n",
      "stages.2.3.MLP.drop1\n",
      "stages.2.3.MLP.fc2\n",
      "stages.2.3.MLP.drop2\n",
      "stages.2.3.drop_path2\n",
      "stages.2.3.res_scale2\n",
      "stages.2.4\n",
      "stages.2.4.norm1\n",
      "stages.2.4.token_mixer\n",
      "stages.2.4.token_mixer.qkv\n",
      "stages.2.4.token_mixer.attn_drop\n",
      "stages.2.4.token_mixer.proj\n",
      "stages.2.4.token_mixer.proj_drop\n",
      "stages.2.4.drop_path1\n",
      "stages.2.4.res_scale1\n",
      "stages.2.4.norm2\n",
      "stages.2.4.MLP\n",
      "stages.2.4.MLP.fc1\n",
      "stages.2.4.MLP.act\n",
      "stages.2.4.MLP.drop1\n",
      "stages.2.4.MLP.fc2\n",
      "stages.2.4.MLP.drop2\n",
      "stages.2.4.drop_path2\n",
      "stages.2.4.res_scale2\n",
      "stages.2.5\n",
      "stages.2.5.norm1\n",
      "stages.2.5.token_mixer\n",
      "stages.2.5.token_mixer.qkv\n",
      "stages.2.5.token_mixer.attn_drop\n",
      "stages.2.5.token_mixer.proj\n",
      "stages.2.5.token_mixer.proj_drop\n",
      "stages.2.5.drop_path1\n",
      "stages.2.5.res_scale1\n",
      "stages.2.5.norm2\n",
      "stages.2.5.MLP\n",
      "stages.2.5.MLP.fc1\n",
      "stages.2.5.MLP.act\n",
      "stages.2.5.MLP.drop1\n",
      "stages.2.5.MLP.fc2\n",
      "stages.2.5.MLP.drop2\n",
      "stages.2.5.drop_path2\n",
      "stages.2.5.res_scale2\n",
      "stages.2.6\n",
      "stages.2.6.norm1\n",
      "stages.2.6.token_mixer\n",
      "stages.2.6.token_mixer.qkv\n",
      "stages.2.6.token_mixer.attn_drop\n",
      "stages.2.6.token_mixer.proj\n",
      "stages.2.6.token_mixer.proj_drop\n",
      "stages.2.6.drop_path1\n",
      "stages.2.6.res_scale1\n",
      "stages.2.6.norm2\n",
      "stages.2.6.MLP\n",
      "stages.2.6.MLP.fc1\n",
      "stages.2.6.MLP.act\n",
      "stages.2.6.MLP.drop1\n",
      "stages.2.6.MLP.fc2\n",
      "stages.2.6.MLP.drop2\n",
      "stages.2.6.drop_path2\n",
      "stages.2.6.res_scale2\n",
      "stages.2.7\n",
      "stages.2.7.norm1\n",
      "stages.2.7.token_mixer\n",
      "stages.2.7.token_mixer.qkv\n",
      "stages.2.7.token_mixer.attn_drop\n",
      "stages.2.7.token_mixer.proj\n",
      "stages.2.7.token_mixer.proj_drop\n",
      "stages.2.7.drop_path1\n",
      "stages.2.7.res_scale1\n",
      "stages.2.7.norm2\n",
      "stages.2.7.MLP\n",
      "stages.2.7.MLP.fc1\n",
      "stages.2.7.MLP.act\n",
      "stages.2.7.MLP.drop1\n",
      "stages.2.7.MLP.fc2\n",
      "stages.2.7.MLP.drop2\n",
      "stages.2.7.drop_path2\n",
      "stages.2.7.res_scale2\n",
      "stages.2.8\n",
      "stages.2.8.norm1\n",
      "stages.2.8.token_mixer\n",
      "stages.2.8.token_mixer.qkv\n",
      "stages.2.8.token_mixer.attn_drop\n",
      "stages.2.8.token_mixer.proj\n",
      "stages.2.8.token_mixer.proj_drop\n",
      "stages.2.8.drop_path1\n",
      "stages.2.8.res_scale1\n",
      "stages.2.8.norm2\n",
      "stages.2.8.MLP\n",
      "stages.2.8.MLP.fc1\n",
      "stages.2.8.MLP.act\n",
      "stages.2.8.MLP.drop1\n",
      "stages.2.8.MLP.fc2\n",
      "stages.2.8.MLP.drop2\n",
      "stages.2.8.drop_path2\n",
      "stages.2.8.res_scale2\n",
      "stages.3\n",
      "stages.3.0\n",
      "stages.3.0.norm1\n",
      "stages.3.0.token_mixer\n",
      "stages.3.0.token_mixer.qkv\n",
      "stages.3.0.token_mixer.attn_drop\n",
      "stages.3.0.token_mixer.proj\n",
      "stages.3.0.token_mixer.proj_drop\n",
      "stages.3.0.drop_path1\n",
      "stages.3.0.res_scale1\n",
      "stages.3.0.norm2\n",
      "stages.3.0.MLP\n",
      "stages.3.0.MLP.fc1\n",
      "stages.3.0.MLP.act\n",
      "stages.3.0.MLP.drop1\n",
      "stages.3.0.MLP.fc2\n",
      "stages.3.0.MLP.drop2\n",
      "stages.3.0.drop_path2\n",
      "stages.3.0.res_scale2\n",
      "stages.3.1\n",
      "stages.3.1.norm1\n",
      "stages.3.1.token_mixer\n",
      "stages.3.1.token_mixer.qkv\n",
      "stages.3.1.token_mixer.attn_drop\n",
      "stages.3.1.token_mixer.proj\n",
      "stages.3.1.token_mixer.proj_drop\n",
      "stages.3.1.drop_path1\n",
      "stages.3.1.res_scale1\n",
      "stages.3.1.norm2\n",
      "stages.3.1.MLP\n",
      "stages.3.1.MLP.fc1\n",
      "stages.3.1.MLP.act\n",
      "stages.3.1.MLP.drop1\n",
      "stages.3.1.MLP.fc2\n",
      "stages.3.1.MLP.drop2\n",
      "stages.3.1.drop_path2\n",
      "stages.3.1.res_scale2\n",
      "stages.3.2\n",
      "stages.3.2.norm1\n",
      "stages.3.2.token_mixer\n",
      "stages.3.2.token_mixer.qkv\n",
      "stages.3.2.token_mixer.attn_drop\n",
      "stages.3.2.token_mixer.proj\n",
      "stages.3.2.token_mixer.proj_drop\n",
      "stages.3.2.drop_path1\n",
      "stages.3.2.res_scale1\n",
      "stages.3.2.norm2\n",
      "stages.3.2.MLP\n",
      "stages.3.2.MLP.fc1\n",
      "stages.3.2.MLP.act\n",
      "stages.3.2.MLP.drop1\n",
      "stages.3.2.MLP.fc2\n",
      "stages.3.2.MLP.drop2\n",
      "stages.3.2.drop_path2\n",
      "stages.3.2.res_scale2\n"
     ]
    }
   ],
   "source": [
    "for name, _ in backbone.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems during setting up LoRA configures\n",
    "1. `task_type`\n",
    "2. unexpected args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:09:32.878760Z",
     "iopub.status.busy": "2025-05-20T10:09:32.877954Z",
     "iopub.status.idle": "2025-05-20T10:09:34.153472Z",
     "shell.execute_reply": "2025-05-20T10:09:34.152886Z",
     "shell.execute_reply.started": "2025-05-20T10:09:32.878733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 269,952 || all params: 23,595,784 || trainable%: 1.1441\n"
     ]
    }
   ],
   "source": [
    "# Wrapping PeftModel to avoid errors\n",
    "from peft import PeftModel\n",
    "\n",
    "class Mamba2DPeftModel(PeftModel):\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # LoRA 관련 LLM 인자 제거\n",
    "        clean_kwargs = {\n",
    "            k: v for k, v in kwargs.items()\n",
    "            if k not in getattr(self, \"special_peft_forward_args\", set())\n",
    "        }\n",
    "        return self.get_base_model()(*args, **clean_kwargs)\n",
    "\n",
    "# Replace backbone with patched version\n",
    "backbone = Mamba2DPeftModel(backbone, lora_cfg)\n",
    "# backbone = backbone.to(dtype=torch.float16).cuda()\n",
    "backbone.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:16:24.754292Z",
     "iopub.status.busy": "2025-05-20T10:16:24.753996Z",
     "iopub.status.idle": "2025-05-20T10:16:24.758269Z",
     "shell.execute_reply": "2025-05-20T10:16:24.757596Z",
     "shell.execute_reply.started": "2025-05-20T10:16:24.754269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from torchmetrics import Accuracy, F1Score, AUROC\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from schedulefree import AdamWScheduleFree\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:09:40.321116Z",
     "iopub.status.busy": "2025-05-20T10:09:40.320841Z",
     "iopub.status.idle": "2025-05-20T10:12:13.963574Z",
     "shell.execute_reply": "2025-05-20T10:12:13.962967Z",
     "shell.execute_reply.started": "2025-05-20T10:09:40.321094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class -> count : {'akiec': 252, 'bcc': 409, 'bkl': 897, 'df': 88, 'mel': 885, 'nv': 5366, 'vasc': 115}\n",
      "alpha : tensor([0.1373, 0.0846, 0.0386, 0.3932, 0.0391, 0.0064, 0.3008])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "counter = Counter()\n",
    "for _, targets in train_dl:       # 배치마다 (inputs, targets) 반환\n",
    "    counter.update(targets.tolist())\n",
    "\n",
    "# Counter -> tensor\n",
    "bincount = torch.tensor([counter[i] for i in range(len(dataset.dx_to_idx))])\n",
    "\n",
    "alpha = 1.0 / bincount.float()\n",
    "alpha /= alpha.sum()\n",
    "\n",
    "print(\"class -> count :\", {cls: counter[idx] for cls, idx in dataset.dx_to_idx.items()})\n",
    "print(\"alpha :\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:12:27.755308Z",
     "iopub.status.busy": "2025-05-20T10:12:27.754987Z",
     "iopub.status.idle": "2025-05-20T10:12:27.760838Z",
     "shell.execute_reply": "2025-05-20T10:12:27.760299Z",
     "shell.execute_reply.started": "2025-05-20T10:12:27.755284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha sum: tensor(1.)\n",
      "alpha values: tensor([0.1373, 0.0846, 0.0386, 0.3932, 0.0391, 0.0064, 0.3008])\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha sum:\", alpha.sum())  # should be 1.0\n",
    "print(\"alpha values:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:12:39.257576Z",
     "iopub.status.busy": "2025-05-20T10:12:39.257088Z",
     "iopub.status.idle": "2025-05-20T10:12:39.263780Z",
     "shell.execute_reply": "2025-05-20T10:12:39.263062Z",
     "shell.execute_reply.started": "2025-05-20T10:12:39.257551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        if isinstance(alpha, (list, torch.Tensor)):\n",
    "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        else:\n",
    "            self.alpha = alpha  # scalar or None\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # 클래스별 alpha 처리\n",
    "        if isinstance(self.alpha, torch.Tensor):\n",
    "            if self.alpha.device != inputs.device:\n",
    "                self.alpha = self.alpha.to(inputs.device)\n",
    "            at = self.alpha[targets]  # shape: (batch,)\n",
    "            focal_loss = at * (1 - pt) ** self.gamma * ce_loss\n",
    "        elif isinstance(self.alpha, (float, int)):\n",
    "            focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        else:\n",
    "            focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:16:28.133836Z",
     "iopub.status.busy": "2025-05-20T10:16:28.133574Z",
     "iopub.status.idle": "2025-05-20T10:16:28.147697Z",
     "shell.execute_reply": "2025-05-20T10:16:28.147192Z",
     "shell.execute_reply.started": "2025-05-20T10:16:28.133816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Mamba2DDerm(L.LightningModule):\n",
    "    def __init__(self,\n",
    "                 backbone: nn.Module,\n",
    "                 head: nn.Module,\n",
    "                 n_classes: int = 7,\n",
    "                 cutmix: bool = False,\n",
    "                 alpha: Optional[torch.Tensor] = None,\n",
    "                 lr: float = 2e-4,\n",
    "                 warmup_pct: float = 0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = torch.tensor([0.1373, 0.0846, 0.0386, 0.3932, 0.0391, 0.0064, 0.3008], dtype=torch.float32)\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"backbone\", \"head\"])\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "        self.norm = nn.LayerNorm(backbone.embed_dim[-1])\n",
    "\n",
    "        # Loss\n",
    "        if cutmix:\n",
    "            self.train_loss = SoftTargetCrossEntropy()\n",
    "            self.val_loss = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            # self.train_loss = FocalLoss(alpha=alpha, gamma=gamma, reduction='mean')\n",
    "            # self.val_loss = FocalLoss(alpha=alpha, gamma=gamma, reduction='mean')\n",
    "            self.train_loss = nn.CrossEntropyLoss(weight=alpha)\n",
    "            self.val_loss = nn.CrossEntropyLoss(weight=alpha)\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=n_classes, average=\"macro\")\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.warmup_pct = warmup_pct\n",
    "\n",
    "        if backbone.channel_last:\n",
    "            self.to(memory_format=torch.channels_last)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.norm(x.mean([-2, -1]))\n",
    "        return self.head(x)\n",
    "\n",
    "    def set_optim_mode(self, mode):\n",
    "        optim = self.optimizers()\n",
    "        if isinstance(optim, list):\n",
    "            for opt in optim: getattr(opt, mode)()\n",
    "        else:\n",
    "            getattr(optim, mode)()\n",
    "\n",
    "    def on_train_epoch_start(self): self.set_optim_mode('train')\n",
    "    def on_train_epoch_end(self): self.set_optim_mode('eval')\n",
    "    def on_save_checkpoint(self, checkpoint): self.set_optim_mode('eval')\n",
    "    def on_validation_start(self): self.set_optim_mode('eval')\n",
    "    def on_predict_start(self): self.set_optim_mode('eval')\n",
    "    def on_test_start(self): self.set_optim_mode('eval')\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.train_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc(preds, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.val_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        self.val_acc.update(preds, y)\n",
    "        self.val_f1.update(preds, y)\n",
    "        self.val_auroc.update(F.softmax(logits, dim=1), y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.val_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", self.val_acc(preds, y))\n",
    "        self.log(\"test_f1\", self.val_f1(preds, y))\n",
    "        self.log(\"test_auroc\", self.val_auroc(F.softmax(logits, dim=1), y))\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val_acc\", self.val_acc.compute(), prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1.compute())\n",
    "        self.log(\"val_auroc\", self.val_auroc.compute())\n",
    "        self.val_acc.reset()\n",
    "        self.val_f1.reset()\n",
    "        self.val_auroc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = [p for p in self.parameters() if p.requires_grad]\n",
    "        warmup_steps = int(self.trainer.estimated_stepping_batches * self.warmup_pct)\n",
    "        return AdamWScheduleFree(params, self.lr, warmup_steps=warmup_steps, weight_decay=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:44:47.925498Z",
     "iopub.status.busy": "2025-05-20T10:44:47.925186Z",
     "iopub.status.idle": "2025-05-20T10:44:47.980564Z",
     "shell.execute_reply": "2025-05-20T10:44:47.979992Z",
     "shell.execute_reply.started": "2025-05-20T10:44:47.925471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    logger.warning(\"No GPU available, using CPU\")\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "head = nn.Linear(512, 7)\n",
    "model = Mamba2DDerm(\n",
    "    backbone=backbone,\n",
    "    head=head,\n",
    "    n_classes=7,\n",
    "    alpha=alpha,  # 계산한 alpha 벡터\n",
    "    gamma=2.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:16:35.967569Z",
     "iopub.status.busy": "2025-05-20T10:16:35.967321Z",
     "iopub.status.idle": "2025-05-20T10:16:35.971937Z",
     "shell.execute_reply": "2025-05-20T10:16:35.971287Z",
     "shell.execute_reply.started": "2025-05-20T10:16:35.967553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Mamba2D\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Mamba2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:16:37.328373Z",
     "iopub.status.busy": "2025-05-20T10:16:37.327674Z",
     "iopub.status.idle": "2025-05-20T10:16:37.483114Z",
     "shell.execute_reply": "2025-05-20T10:16:37.482452Z",
     "shell.execute_reply.started": "2025-05-20T10:16:37.328349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Mamba2D\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:47:13.000847Z",
     "iopub.status.busy": "2025-05-20T07:47:13.000521Z",
     "iopub.status.idle": "2025-05-20T07:48:01.657864Z",
     "shell.execute_reply": "2025-05-20T07:48:01.657141Z",
     "shell.execute_reply.started": "2025-05-20T07:47:13.000821Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-20 07:47:13--  https://github.com/cocoalex00/Mamba2D/releases/download/v1.0.0/M2D-T-ImNet-300-ep-EMA.ckpt\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/917684738/d08b711a-ba1e-4c5d-9edd-2c191fb953b4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250520%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250520T074713Z&X-Amz-Expires=300&X-Amz-Signature=54aa41b50aafd55db5c43b201dc53fa4bf827a512bd34d42556bfcbb8120b7a1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DM2D-T-ImNet-300-ep-EMA.ckpt&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-05-20 07:47:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/917684738/d08b711a-ba1e-4c5d-9edd-2c191fb953b4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250520%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250520T074713Z&X-Amz-Expires=300&X-Amz-Signature=54aa41b50aafd55db5c43b201dc53fa4bf827a512bd34d42556bfcbb8120b7a1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DM2D-T-ImNet-300-ep-EMA.ckpt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 427449046 (408M) [application/octet-stream]\n",
      "Saving to: ‘M2D-T-ImNet-300-ep-EMA.ckpt’\n",
      "\n",
      "M2D-T-ImNet-300-ep- 100%[===================>] 407.65M  9.25MB/s    in 47s     \n",
      "\n",
      "2025-05-20 07:48:01 (8.76 MB/s) - ‘M2D-T-ImNet-300-ep-EMA.ckpt’ saved [427449046/427449046]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/cocoalex00/Mamba2D/releases/download/v1.0.0/M2D-T-ImNet-300-ep-EMA.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:44:53.233426Z",
     "iopub.status.busy": "2025-05-20T10:44:53.232805Z",
     "iopub.status.idle": "2025-05-20T10:44:53.762128Z",
     "shell.execute_reply": "2025-05-20T10:44:53.761612Z",
     "shell.execute_reply.started": "2025-05-20T10:44:53.233402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 사전 학습 모델 로드\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint = torch.load(\"M2D-T-ImNet-300-ep-EMA.ckpt\", map_location=device)\n",
    "\n",
    "# state_dict 키가 있는 경우와 없는 경우 자동 처리\n",
    "if \"state_dict\" in checkpoint:\n",
    "    checkpoint_dict = checkpoint[\"state_dict\"]\n",
    "    logger.info(\"Loaded Lightning-style checkpoint with 'state_dict' key\")\n",
    "else:\n",
    "    checkpoint_dict = checkpoint\n",
    "    logger.info(\"Loaded raw state_dict checkpoint\")\n",
    "\n",
    "model.backbone.load_state_dict(checkpoint_dict, strict=False)\n",
    "\n",
    "# model = model.to(dtype=torch.float16, device=device)\n",
    "logger.info(\"Loaded pretrained Mamba2D checkpoint onto %s\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:17:02.950459Z",
     "iopub.status.busy": "2025-05-20T10:17:02.950150Z",
     "iopub.status.idle": "2025-05-20T10:17:02.975376Z",
     "shell.execute_reply": "2025-05-20T10:17:02.974817Z",
     "shell.execute_reply.started": "2025-05-20T10:17:02.950435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "\n",
    "# 콜백 정의\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"vmamba-ham10k-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:19:14.565703Z",
     "iopub.status.busy": "2025-05-20T10:19:14.565106Z",
     "iopub.status.idle": "2025-05-20T10:19:14.612276Z",
     "shell.execute_reply": "2025-05-20T10:19:14.611772Z",
     "shell.execute_reply.started": "2025-05-20T10:19:14.565680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 트레이너 설정\n",
    "trainer = L.Trainer(\n",
    "    # fast_dev_run=True,       # [TEST] 한 에폭만 수행\n",
    "    # limit_train_batches=0.01,# [TEST] 전체 train 데이터의 1%만 사용\n",
    "    # limit_val_batches=0.01,  # [TEST] 전체 val 데이터의 1%만 사용\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    # devices=2,                # ddp\n",
    "    # strategy=\"ddp\",           # ddp\n",
    "    # precision=\"16-mixed\",    # 혼합 정밀도 훈련\n",
    "    precision=\"32-true\",\n",
    "    max_epochs=2,             # 에폭 수 증가\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "    gradient_clip_val=1.0,    # 그래디언트 클리핑 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:19:17.792560Z",
     "iopub.status.busy": "2025-05-20T10:19:17.791809Z",
     "iopub.status.idle": "2025-05-20T10:40:43.208750Z",
     "shell.execute_reply": "2025-05-20T10:40:43.208010Z",
     "shell.execute_reply.started": "2025-05-20T10:19:17.792527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: Loading `train_dataloader` to estimate number of stepping batches.\n",
      "INFO: \n",
      "  | Name       | Type               | Params | Mode\n",
      "---------------------------------------------------------\n",
      "0 | backbone   | Mamba2DPeftModel   | 23.6 M | eval\n",
      "1 | head       | Linear             | 3.6 K  | eval\n",
      "2 | norm       | LayerNorm          | 1.0 K  | eval\n",
      "3 | train_loss | CrossEntropyLoss   | 0      | eval\n",
      "4 | val_loss   | CrossEntropyLoss   | 0      | eval\n",
      "5 | train_acc  | MulticlassAccuracy | 0      | eval\n",
      "6 | val_acc    | MulticlassAccuracy | 0      | eval\n",
      "7 | val_f1     | MulticlassF1Score  | 0      | eval\n",
      "8 | val_auroc  | MulticlassAUROC    | 0      | eval\n",
      "---------------------------------------------------------\n",
      "274 K     Trainable params\n",
      "23.3 M    Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.402    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "865       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6522a07d51a94b859bfcc8d839ec35e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Metric val_loss improved by 0.392 >= min_delta = 0.0. New best score: 1.429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Metric val_loss improved by 0.163 >= min_delta = 0.0. New best score: 1.265\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcf0773199e48bca0e38576c0eccf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5908183455467224     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23895041644573212    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42435598373413086    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.418202519416809     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5908183455467224    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23895041644573212   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42435598373413086   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.418202519416809    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "try:\n",
    "    logger.info(\"Starting training\")\n",
    "    trainer.fit(model, train_dl, val_dl)\n",
    "    \n",
    "    # 테스트셋에서 평가\n",
    "    trainer.test(model, test_dl)\n",
    "    \n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), \"mamba2d_ham10k_final.pt\")\n",
    "    \n",
    "    # LoRA 가중치만 저장 (용량 절약)\n",
    "    model.backbone.save_pretrained(\"mamba2d_ham10k_lora_weights\")\n",
    "    logger.info(\"Saved model weights\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Training failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:45:10.229051Z",
     "iopub.status.busy": "2025-05-20T10:45:10.228796Z",
     "iopub.status.idle": "2025-05-20T10:45:41.610500Z",
     "shell.execute_reply": "2025-05-20T10:45:41.609939Z",
     "shell.execute_reply.started": "2025-05-20T10:45:10.229032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4901a34d09493cb9d80ac36c4836de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03393213450908661    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.149177685379982     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.028465287759900093    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.156681537628174     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03393213450908661   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.149177685379982    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.028465287759900093   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.156681537628174    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.156681537628174,\n",
       "  'test_acc': 0.03393213450908661,\n",
       "  'test_f1': 0.028465287759900093,\n",
       "  'test_auroc': 0.149177685379982}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6115726,
     "sourceId": 9945731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

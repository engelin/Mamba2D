{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nbase_skin_dir = os.path.join('..', 'input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eeaf251fac6f58be9749219ba274d089ba2a42e"},"cell_type":"code","source":"imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'dermatofibroma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38351edb3401ca5dcc1a0a34622341face0384e2"},"cell_type":"code","source":"tile_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\ntile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\ntile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \ntile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\ntile_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f0ad3263d12ba1ac6a929061912d35d98648ef6"},"cell_type":"code","source":"tile_df.describe(exclude=[np.number])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1ebe72192d31106f72fc0a6152e90004c87d2186"},"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (10, 5))\ntile_df['cell_type'].value_counts().plot(kind='bar', ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"635e18743a35e374a5c070d02f34849b95d5ba74"},"cell_type":"code","source":"# load in all of the images\nfrom skimage.io import imread\ntile_df['image'] = tile_df['path'].map(imread)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c90459cfb9487d12b186abe08221092a9a7f91a"},"cell_type":"code","source":"# see the image size distribution\ntile_df['image'].map(lambda x: x.shape).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ff7f5ce5ac84524c6b1f91152ab377d5549cc3a"},"cell_type":"markdown","source":"# Show off a few in each category"},{"metadata":{"trusted":true,"_uuid":"ef4f68f1782a0426ea305db0bd0408d96f88ac25"},"cell_type":"code","source":"n_samples = 5\nfig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\nfor n_axs, (type_name, type_rows) in zip(m_axs, \n                                         tile_df.sort_values(['cell_type']).groupby('cell_type')):\n    n_axs[0].set_title(type_name)\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=2018).iterrows()):\n        c_ax.imshow(c_row['image'])\n        c_ax.axis('off')\nfig.savefig('category_samples.png', dpi=300)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38f051f20bddd90382e3d1e0036d1bad55ffbaff"},"cell_type":"markdown","source":"## Get Average Color Information\nHere we get and normalize all of the color channel information"},{"metadata":{"trusted":true,"_uuid":"207c2cfc0c52a1f1e305ee96f05b459ab1d73859"},"cell_type":"code","source":"rgb_info_df = tile_df.apply(lambda x: pd.Series({'{}_mean'.format(k): v for k, v in \n                                  zip(['Red', 'Green', 'Blue'], \n                                      np.mean(x['image'], (0, 1)))}),1)\ngray_col_vec = rgb_info_df.apply(lambda x: np.mean(x), 1)\nfor c_col in rgb_info_df.columns:\n    rgb_info_df[c_col] = rgb_info_df[c_col]/gray_col_vec\nrgb_info_df['Gray_mean'] = gray_col_vec\nrgb_info_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"422eb155b4504f7bd72b10cce71f7e3a2b1c1c2d"},"cell_type":"code","source":"for c_col in rgb_info_df.columns:\n    tile_df[c_col] = rgb_info_df[c_col].values # we cant afford a copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"536ec6dc09db19173de8147f33e041a85f7b8501"},"cell_type":"code","source":"sns.pairplot(tile_df[['Red_mean', 'Green_mean', 'Blue_mean', 'Gray_mean', 'cell_type']], \n             hue='cell_type', plot_kws = {'alpha': 0.5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"418ca09b7f6c1ce6c6799aa806980bd91810d27f"},"cell_type":"markdown","source":"# Show Color Range\nShow how the mean color channel values affect images"},{"metadata":{"trusted":true,"_uuid":"55944a8696f1abadf95116da6b914d40f44b746d"},"cell_type":"code","source":"n_samples = 5\nfor sample_col in ['Red_mean', 'Green_mean', 'Blue_mean', 'Gray_mean']:\n    fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n    def take_n_space(in_rows, val_col, n):\n        s_rows = in_rows.sort_values([val_col])\n        s_idx = np.linspace(0, s_rows.shape[0]-1, n, dtype=int)\n        return s_rows.iloc[s_idx]\n    for n_axs, (type_name, type_rows) in zip(m_axs, \n                                             tile_df.sort_values(['cell_type']).groupby('cell_type')):\n\n        for c_ax, (_, c_row) in zip(n_axs, \n                                    take_n_space(type_rows, \n                                                 sample_col,\n                                                 n_samples).iterrows()):\n            c_ax.imshow(c_row['image'])\n            c_ax.axis('off')\n            c_ax.set_title('{:2.2f}'.format(c_row[sample_col]))\n        n_axs[0].set_title(type_name)\n    fig.savefig('{}_samples.png'.format(sample_col), dpi=300)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb2811c0729d5f33522aa7c01b08779f0d3071e4"},"cell_type":"markdown","source":"# Make a nice cover image\nMake a cover image for the dataset using all of the tiles"},{"metadata":{"trusted":true,"_uuid":"2d81730dc475f140cc3a6a4b25db14f1d7b74d1f"},"cell_type":"code","source":"from skimage.util import montage\nrgb_stack = np.stack(tile_df.\\\n                     sort_values(['cell_type', 'Red_mean'])['image'].\\\n                     map(lambda x: x[::5, ::5]).values, 0)\nrgb_montage = np.stack([montage(rgb_stack[:, :, :, i]) for i in range(rgb_stack.shape[3])], -1)\nprint(rgb_montage.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b90d85b849df23776e09b8b719ae8a917297634"},"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (20, 20), dpi=300)\nax1.imshow(rgb_montage)\nfig.savefig('nice_montage.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"152b5c84bfca5e6d25d173e983d464676990ddf5"},"cell_type":"code","source":"from skimage.io import imsave\n# this is a big file, imsave('full_dataset_montage.png', rgb_montage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ccf160b56285afb56c91de2d74069b699fe4ba2"},"cell_type":"markdown","source":"# Make an MNIST Like Dataset\nWe can make an MNIST-like dataset by flattening the images into vectors and exporting them"},{"metadata":{"trusted":true,"_uuid":"b2b3ac53165b6d05d291c985aa30b008ad95c155"},"cell_type":"code","source":"tile_df[['cell_type_idx', 'cell_type']].sort_values('cell_type_idx').drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9af9a97e62435ac555ae7a8e215db6d7fcf6706"},"cell_type":"code","source":"from PIL import Image\ndef package_mnist_df(in_rows, \n                     image_col_name = 'image',\n                     label_col_name = 'cell_type_idx',\n                     image_shape=(28, 28), \n                     image_mode='RGB',\n                     label_first=False\n                    ):\n    out_vec_list = in_rows[image_col_name].map(lambda x: \n                                               np.array(Image.\\\n                                                        fromarray(x).\\\n                                                        resize(image_shape, resample=Image.LANCZOS).\\\n                                                        convert(image_mode)).ravel())\n    out_vec = np.stack(out_vec_list, 0)\n    out_df = pd.DataFrame(out_vec)\n    n_col_names =  ['pixel{:04d}'.format(i) for i in range(out_vec.shape[1])]\n    out_df.columns = n_col_names\n    out_df['label'] = in_rows[label_col_name].values.copy()\n    if label_first:\n        return out_df[['label']+n_col_names]\n    else:\n        return out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7570d47b0c0b0e7fb3076cba6afd50004693dd0d"},"cell_type":"code","source":"from itertools import product\nfor img_side_dim, img_mode in product([8, 28, 64, 128], ['L', 'RGB']):\n    if (img_side_dim==128) and (img_mode=='RGB'):\n        # 128x128xRGB is a biggie\n        break\n    out_df = package_mnist_df(tile_df, \n                              image_shape=(img_side_dim, img_side_dim),\n                             image_mode=img_mode)\n    out_path = f'hmnist_{img_side_dim}_{img_side_dim}_{img_mode}.csv'\n    out_df.to_csv(out_path, index=False)\n    print(f'Saved {out_df.shape} -> {out_path}: {os.stat(out_path).st_size/1024:2.1f}kb')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfa895a02426ae789b1e544bf2598aef92424c68"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}